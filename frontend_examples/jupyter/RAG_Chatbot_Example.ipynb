{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Chatbot - Jupyter Notebook Example\n",
    "\n",
    "This notebook demonstrates how to use the RAG (Retrieval Augmented Generation) chatbot system from within a Jupyter environment.\n",
    "\n",
    "## Features Covered:\n",
    "- Basic chat functionality\n",
    "- Conversation management\n",
    "- Source document analysis\n",
    "- Batch processing\n",
    "- Data visualization\n",
    "- Export capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install requests pandas matplotlib seaborn plotly ipywidgets\n",
    "\n",
    "# Import libraries\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from typing import List, Dict, Any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Client Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "RAG_API_URL = \"http://localhost:8000\"  # Change this to your RAG service URL\n",
    "# For AWS Lambda: \"https://your-api-id.execute-api.region.amazonaws.com/dev\"\n",
    "\n",
    "TIMEOUT = 30\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "# Initialize session\n",
    "session = requests.Session()\n",
    "session.headers.update({\n",
    "    'Content-Type': 'application/json',\n",
    "    'User-Agent': 'RAG-Jupyter-Client/1.0'\n",
    "})\n",
    "\n",
    "print(f\"üöÄ RAG Client configured for: {RAG_API_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_health() -> bool:\n",
    "    \"\"\"Check if RAG service is healthy\"\"\"\n",
    "    try:\n",
    "        response = session.get(f\"{RAG_API_URL}/health\", timeout=TIMEOUT)\n",
    "        return response.status_code == 200\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def send_query(query: str, conversation_id: str = None, max_results: int = 3) -> Dict[str, Any]:\n",
    "    \"\"\"Send query to RAG service\"\"\"\n",
    "    payload = {\n",
    "        \"query\": query,\n",
    "        \"max_results\": max_results\n",
    "    }\n",
    "    \n",
    "    if conversation_id:\n",
    "        payload[\"conversation_id\"] = conversation_id\n",
    "    \n",
    "    try:\n",
    "        response = session.post(\n",
    "            f\"{RAG_API_URL}/chat\",\n",
    "            json=payload,\n",
    "            timeout=TIMEOUT\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            return {\n",
    "                \"error\": f\"HTTP {response.status_code}: {response.text}\",\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"error\": str(e),\n",
    "            \"status\": \"error\"\n",
    "        }\n",
    "\n",
    "def format_response(response: Dict[str, Any]) -> str:\n",
    "    \"\"\"Format response for display\"\"\"\n",
    "    if response.get(\"status\") == \"error\":\n",
    "        return f\"‚ùå Error: {response.get('error', 'Unknown error')}\"\n",
    "    \n",
    "    output = []\n",
    "    output.append(f\"ü§ñ **Answer:** {response.get('answer', 'No answer provided')}\")\n",
    "    \n",
    "    sources = response.get(\"sources\", [])\n",
    "    if sources:\n",
    "        output.append(\"\\nüìö **Sources:**\")\n",
    "        for i, source in enumerate(sources[:3], 1):\n",
    "            source_name = source.get(\"source\", \"Unknown\")\n",
    "            score = source.get(\"score\", 0)\n",
    "            page = source.get(\"page\")\n",
    "            page_info = f\" (page {page})\" if page else \"\"\n",
    "            output.append(f\"  {i}. {source_name}{page_info} - Relevance: {score:.2f}\")\n",
    "    \n",
    "    processing_time = response.get(\"processing_time\")\n",
    "    if processing_time:\n",
    "        cached_info = \" (cached)\" if response.get(\"cached\") else \"\"\n",
    "        output.append(f\"\\n‚è±Ô∏è Processing time: {processing_time:.2f}s{cached_info}\")\n",
    "    \n",
    "    return \"\\n\".join(output)\n",
    "\n",
    "# Test connection\n",
    "if check_health():\n",
    "    print(\"‚úÖ RAG service is healthy\")\n",
    "else:\n",
    "    print(\"‚ùå RAG service is not responding. Please check the URL and service status.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Chat Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple query example\n",
    "query = \"What is machine learning?\"\n",
    "response = send_query(query)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(\"=\" * 50)\n",
    "print(format_response(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a conversation\n",
    "conversation_id = None\n",
    "conversation_history = []\n",
    "\n",
    "queries = [\n",
    "    \"What is artificial intelligence?\",\n",
    "    \"How does it relate to machine learning?\",\n",
    "    \"Can you give me some examples?\"\n",
    "]\n",
    "\n",
    "print(\"üó£Ô∏è **Conversation Example**\\n\")\n",
    "\n",
    "for i, query in enumerate(queries, 1):\n",
    "    print(f\"**Turn {i}**\")\n",
    "    print(f\"üë§ Human: {query}\")\n",
    "    \n",
    "    response = send_query(query, conversation_id)\n",
    "    \n",
    "    if response.get(\"status\") != \"error\":\n",
    "        conversation_id = response.get(\"conversation_id\")\n",
    "        answer = response.get(\"answer\", \"No answer\")\n",
    "        print(f\"ü§ñ Assistant: {answer}\")\n",
    "        \n",
    "        # Store conversation\n",
    "        conversation_history.append({\n",
    "            \"turn\": i,\n",
    "            \"query\": query,\n",
    "            \"response\": response,\n",
    "            \"timestamp\": datetime.now()\n",
    "        })\n",
    "    else:\n",
    "        print(f\"‚ùå Error: {response.get('error')}\")\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "\n",
    "print(f\"\\nüìù Conversation ID: {conversation_id}\")\n",
    "print(f\"üìä Total turns: {len(conversation_history)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Query Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch processing example\n",
    "batch_queries = [\n",
    "    \"What is deep learning?\",\n",
    "    \"Explain neural networks\",\n",
    "    \"What is natural language processing?\",\n",
    "    \"How does computer vision work?\",\n",
    "    \"What are the applications of AI in healthcare?\"\n",
    "]\n",
    "\n",
    "batch_results = []\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"üîÑ Processing {len(batch_queries)} queries...\\n\")\n",
    "\n",
    "for i, query in enumerate(batch_queries, 1):\n",
    "    print(f\"Processing {i}/{len(batch_queries)}: {query[:50]}...\")\n",
    "    \n",
    "    query_start = time.time()\n",
    "    response = send_query(query)\n",
    "    query_time = time.time() - query_start\n",
    "    \n",
    "    result = {\n",
    "        \"query\": query,\n",
    "        \"response\": response,\n",
    "        \"query_time\": query_time,\n",
    "        \"timestamp\": datetime.now(),\n",
    "        \"success\": response.get(\"status\") != \"error\"\n",
    "    }\n",
    "    \n",
    "    batch_results.append(result)\n",
    "    \n",
    "    # Small delay to avoid overwhelming the service\n",
    "    time.sleep(0.5)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "successful_queries = sum(1 for r in batch_results if r[\"success\"])\n",
    "\n",
    "print(f\"\\n‚úÖ Batch processing completed!\")\n",
    "print(f\"üìä Success rate: {successful_queries}/{len(batch_queries)} ({successful_queries/len(batch_queries)*100:.1f}%)\")\n",
    "print(f\"‚è±Ô∏è Total time: {total_time:.2f}s\")\n",
    "print(f\"‚ö° Average time per query: {total_time/len(batch_queries):.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame from batch results\n",
    "df_results = pd.DataFrame([\n",
    "    {\n",
    "        'query': r['query'],\n",
    "        'query_length': len(r['query']),\n",
    "        'processing_time': r['response'].get('processing_time', 0),\n",
    "        'query_time': r['query_time'],\n",
    "        'cached': r['response'].get('cached', False),\n",
    "        'num_sources': len(r['response'].get('sources', [])),\n",
    "        'success': r['success'],\n",
    "        'answer_length': len(r['response'].get('answer', '')) if r['success'] else 0\n",
    "    }\n",
    "    for r in batch_results\n",
    "])\n",
    "\n",
    "print(\"üìä **Batch Results Summary:**\")\n",
    "display(df_results.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing time analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('RAG System Performance Analysis', fontsize=16)\n",
    "\n",
    "# Processing time distribution\n",
    "axes[0, 0].hist(df_results['processing_time'], bins=10, alpha=0.7, color='skyblue')\n",
    "axes[0, 0].set_title('Processing Time Distribution')\n",
    "axes[0, 0].set_xlabel('Processing Time (s)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Query length vs processing time\n",
    "axes[0, 1].scatter(df_results['query_length'], df_results['processing_time'], alpha=0.7)\n",
    "axes[0, 1].set_title('Query Length vs Processing Time')\n",
    "axes[0, 1].set_xlabel('Query Length (characters)')\n",
    "axes[0, 1].set_ylabel('Processing Time (s)')\n",
    "\n",
    "# Number of sources returned\n",
    "axes[1, 0].bar(range(len(df_results)), df_results['num_sources'], alpha=0.7, color='lightgreen')\n",
    "axes[1, 0].set_title('Number of Sources per Query')\n",
    "axes[1, 0].set_xlabel('Query Index')\n",
    "axes[1, 0].set_ylabel('Number of Sources')\n",
    "\n",
    "# Answer length distribution\n",
    "successful_results = df_results[df_results['success']]\n",
    "axes[1, 1].hist(successful_results['answer_length'], bins=10, alpha=0.7, color='orange')\n",
    "axes[1, 1].set_title('Answer Length Distribution')\n",
    "axes[1, 1].set_xlabel('Answer Length (characters)')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze source documents\n",
    "all_sources = []\n",
    "\n",
    "for result in batch_results:\n",
    "    if result['success']:\n",
    "        sources = result['response'].get('sources', [])\n",
    "        for source in sources:\n",
    "            source_info = {\n",
    "                'query': result['query'],\n",
    "                'source_name': source.get('source', 'Unknown'),\n",
    "                'score': source.get('score', 0),\n",
    "                'page': source.get('page'),\n",
    "                'text_length': len(source.get('text', ''))\n",
    "            }\n",
    "            all_sources.append(source_info)\n",
    "\n",
    "if all_sources:\n",
    "    df_sources = pd.DataFrame(all_sources)\n",
    "    \n",
    "    print(f\"üìö **Source Documents Analysis** ({len(all_sources)} total sources)\\n\")\n",
    "    \n",
    "    # Most frequently cited sources\n",
    "    source_counts = df_sources['source_name'].value_counts().head(10)\n",
    "    print(\"**Most Frequently Cited Sources:**\")\n",
    "    for source, count in source_counts.items():\n",
    "        print(f\"  ‚Ä¢ {source}: {count} times\")\n",
    "    \n",
    "    # Average relevance scores\n",
    "    avg_scores = df_sources.groupby('source_name')['score'].agg(['mean', 'count']).round(3)\n",
    "    avg_scores = avg_scores[avg_scores['count'] >= 2].sort_values('mean', ascending=False)\n",
    "    \n",
    "    print(\"\\n**Average Relevance Scores (sources with 2+ citations):**\")\n",
    "    display(avg_scores.head(10))\n",
    "    \n",
    "    # Visualize source distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    source_counts.head(8).plot(kind='bar')\n",
    "    plt.title('Top Source Documents')\n",
    "    plt.xlabel('Source Document')\n",
    "    plt.ylabel('Citation Count')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(df_sources['score'], bins=20, alpha=0.7, color='lightcoral')\n",
    "    plt.title('Relevance Score Distribution')\n",
    "    plt.xlabel('Relevance Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No source information available from the queries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Query Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive widget-based interface (requires ipywidgets)\n",
    "try:\n",
    "    from ipywidgets import interact, widgets, VBox, HBox\n",
    "    from IPython.display import display, clear_output, Markdown\n",
    "    \n",
    "    # Create widgets\n",
    "    query_input = widgets.Text(\n",
    "        placeholder='Enter your question here...',\n",
    "        description='Query:',\n",
    "        layout=widgets.Layout(width='500px')\n",
    "    )\n",
    "    \n",
    "    max_results_slider = widgets.IntSlider(\n",
    "        value=3,\n",
    "        min=1,\n",
    "        max=10,\n",
    "        description='Max Results:'\n",
    "    )\n",
    "    \n",
    "    send_button = widgets.Button(\n",
    "        description='Send Query',\n",
    "        button_style='primary',\n",
    "        icon='paper-plane'\n",
    "    )\n",
    "    \n",
    "    clear_button = widgets.Button(\n",
    "        description='Clear Output',\n",
    "        button_style='warning',\n",
    "        icon='trash'\n",
    "    )\n",
    "    \n",
    "    output_area = widgets.Output()\n",
    "    \n",
    "    # Widget interactions\n",
    "    def send_query_widget(b):\n",
    "        with output_area:\n",
    "            query = query_input.value.strip()\n",
    "            if not query:\n",
    "                print(\"Please enter a query.\")\n",
    "                return\n",
    "            \n",
    "            print(f\"üîç Processing: {query}\")\n",
    "            response = send_query(query, max_results=max_results_slider.value)\n",
    "            print(\"\\n\" + format_response(response))\n",
    "            print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "    \n",
    "    def clear_output_widget(b):\n",
    "        output_area.clear_output()\n",
    "    \n",
    "    # Connect button events\n",
    "    send_button.on_click(send_query_widget)\n",
    "    clear_button.on_click(clear_output_widget)\n",
    "    \n",
    "    # Handle Enter key\n",
    "    def handle_enter(sender):\n",
    "        send_query_widget(None)\n",
    "    \n",
    "    query_input.on_submit(handle_enter)\n",
    "    \n",
    "    # Display interface\n",
    "    print(\"üéõÔ∏è **Interactive Query Interface**\")\n",
    "    \n",
    "    interface = VBox([\n",
    "        HBox([query_input, max_results_slider]),\n",
    "        HBox([send_button, clear_button]),\n",
    "        output_area\n",
    "    ])\n",
    "    \n",
    "    display(interface)\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"üí° Install ipywidgets for interactive interface: pip install ipywidgets\")\n",
    "    print(\"   Then restart the kernel and run this cell again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export and Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to various formats\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Export to JSON\n",
    "export_data = {\n",
    "    'timestamp': timestamp,\n",
    "    'api_url': RAG_API_URL,\n",
    "    'batch_results': [\n",
    "        {\n",
    "            'query': r['query'],\n",
    "            'response': r['response'],\n",
    "            'processing_time': r['query_time'],\n",
    "            'timestamp': r['timestamp'].isoformat(),\n",
    "            'success': r['success']\n",
    "        }\n",
    "        for r in batch_results\n",
    "    ],\n",
    "    'conversation_history': [\n",
    "        {\n",
    "            'turn': h['turn'],\n",
    "            'query': h['query'],\n",
    "            'response': h['response'],\n",
    "            'timestamp': h['timestamp'].isoformat()\n",
    "        }\n",
    "        for h in conversation_history\n",
    "    ],\n",
    "    'summary': {\n",
    "        'total_queries': len(batch_results),\n",
    "        'successful_queries': successful_queries,\n",
    "        'success_rate': successful_queries / len(batch_results) if batch_results else 0,\n",
    "        'average_processing_time': df_results['processing_time'].mean() if not df_results.empty else 0,\n",
    "        'total_sources_found': len(all_sources) if all_sources else 0\n",
    "    }\n",
    "}\n",
    "\n",
    "json_filename = f\"rag_session_{timestamp}.json\"\n",
    "with open(json_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(export_data, f, indent=2, ensure_ascii=False, default=str)\n",
    "\n",
    "print(f\"üíæ Session data exported to: {json_filename}\")\n",
    "\n",
    "# Export DataFrame to CSV\n",
    "if not df_results.empty:\n",
    "    csv_filename = f\"rag_results_{timestamp}.csv\"\n",
    "    df_results.to_csv(csv_filename, index=False)\n",
    "    print(f\"üìä Results DataFrame exported to: {csv_filename}\")\n",
    "\n",
    "# Generate summary report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìã **SESSION SUMMARY REPORT**\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üïê Session time: {timestamp}\")\n",
    "print(f\"üîó API URL: {RAG_API_URL}\")\n",
    "print(f\"üìù Total queries processed: {len(batch_results)}\")\n",
    "print(f\"‚úÖ Successful queries: {successful_queries}\")\n",
    "print(f\"üìä Success rate: {successful_queries/len(batch_results)*100:.1f}%\" if batch_results else \"N/A\")\n",
    "if not df_results.empty:\n",
    "    print(f\"‚è±Ô∏è Average processing time: {df_results['processing_time'].mean():.2f}s\")\n",
    "    print(f\"üìö Total sources retrieved: {len(all_sources)}\")\n",
    "    print(f\"üîç Average sources per query: {df_results['num_sources'].mean():.1f}\")\n",
    "print(f\"üó£Ô∏è Conversation turns: {len(conversation_history)}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance benchmarking\n",
    "def benchmark_queries(queries: List[str], iterations: int = 3) -> Dict[str, Any]:\n",
    "    \"\"\"Benchmark query performance\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for query in queries:\n",
    "        query_times = []\n",
    "        for i in range(iterations):\n",
    "            start_time = time.time()\n",
    "            response = send_query(query)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            if response.get('status') != 'error':\n",
    "                query_times.append(end_time - start_time)\n",
    "            \n",
    "            time.sleep(0.1)  # Small delay between iterations\n",
    "        \n",
    "        if query_times:\n",
    "            results.append({\n",
    "                'query': query,\n",
    "                'avg_time': sum(query_times) / len(query_times),\n",
    "                'min_time': min(query_times),\n",
    "                'max_time': max(query_times),\n",
    "                'iterations': len(query_times)\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run benchmark\n",
    "benchmark_queries_sample = [\n",
    "    \"What is AI?\",\n",
    "    \"Explain machine learning algorithms\",\n",
    "    \"How does natural language processing work in modern applications?\"\n",
    "]\n",
    "\n",
    "print(\"üèÉ‚Äç‚ôÇÔ∏è Running performance benchmark...\")\n",
    "benchmark_results = benchmark_queries(benchmark_queries_sample, iterations=3)\n",
    "\n",
    "if benchmark_results:\n",
    "    df_benchmark = pd.DataFrame(benchmark_results)\n",
    "    \n",
    "    print(\"\\n‚ö° **Performance Benchmark Results:**\")\n",
    "    display(df_benchmark)\n",
    "    \n",
    "    # Visualize benchmark results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    x_pos = range(len(df_benchmark))\n",
    "    plt.bar(x_pos, df_benchmark['avg_time'], \n",
    "            yerr=[df_benchmark['avg_time'] - df_benchmark['min_time'],\n",
    "                  df_benchmark['max_time'] - df_benchmark['avg_time']],\n",
    "            capsize=5, alpha=0.7, color='lightblue')\n",
    "    \n",
    "    plt.xlabel('Query')\n",
    "    plt.ylabel('Response Time (seconds)')\n",
    "    plt.title('Query Performance Benchmark')\n",
    "    plt.xticks(x_pos, [f\"Q{i+1}\" for i in range(len(df_benchmark))], rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Performance summary\n",
    "    print(f\"\\nüìä **Benchmark Summary:**\")\n",
    "    print(f\"  ‚Ä¢ Average response time: {df_benchmark['avg_time'].mean():.2f}s\")\n",
    "    print(f\"  ‚Ä¢ Fastest query: {df_benchmark['min_time'].min():.2f}s\")\n",
    "    print(f\"  ‚Ä¢ Slowest query: {df_benchmark['max_time'].max():.2f}s\")\nelse:\n    print(\"‚ùå Benchmark failed - no successful queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated comprehensive usage of the RAG chatbot system including:\n",
    "\n",
    "- ‚úÖ Basic query functionality\n",
    "- ‚úÖ Conversation management\n",
    "- ‚úÖ Batch processing capabilities\n",
    "- ‚úÖ Performance analysis and visualization\n",
    "- ‚úÖ Source document analysis\n",
    "- ‚úÖ Interactive query interface\n",
    "- ‚úÖ Data export and reporting\n",
    "- ‚úÖ Performance benchmarking\n",
    "\n",
    "The RAG system provides a powerful interface for accessing and querying your enterprise knowledge base with context-aware responses and source attribution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}